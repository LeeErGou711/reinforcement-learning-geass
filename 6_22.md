# theory lecture 1
## basics of ML
### regression,  classification, logistic regression, model evaluation are familar
### PAC learning
- PAC = probably approximately correct. something I do not know 
- true error
- consistent
- version space
- $\epsilon$-exhausted
## basics of DL
### NN, CNN, BP are familar
### Recurrent neural network

#### LSTM Long short-term meeory
between two perceptrons, decide what to forget and what to insert based on the object function $f$
#### GRU Gated recurrent unit
